#' Query https://pesticidecompendium.bcpc.org
#'
#' Query the BCPC Compendium of Pesticide Common Names
#' \url{https://pesticidecompendium.bcpc.org}
#' formerly known as Alan Woods Compendium of Pesticide Common Names
#' @import xml2
#'
#' @param  query character; search string
#' @param from character; type of input ('cas' or 'name')
#' @param verbose logical; print message during processing to console?
#' @param ... additional arguments to internal utility functions
#' @param type deprecated
#' @return A list of eight entries: common-name, status, preferred IUPAC Name,
#' IUPAC Name, cas, formula, activity, subactivity, inchikey, inchi and source
#' url.
#' @note for from = 'cas' only the first matched link is returned.
#' Please respect Copyright, Terms and Conditions
#' \url{https://pesticidecompendium.bcpc.org/legal.html}!
#' @references Eduard Szöcs, Tamás Stirling, Eric R. Scott, Andreas Scharmüller,
#' Ralf B. Schäfer (2020). webchem: An R Package to Retrieve Chemical
#' Information from the Web. Journal of Statistical Software, 93(13).
#' \doi{10.18637/jss.v093.i13}.
#' @export
#' @examples
#' \dontrun{
#' bcpc_query('Fluazinam', from = 'name')
#' out <- bcpc_query(c('Fluazinam', 'Diclofop'), from = 'name')
#' out
#' # extract subactivity from object
#' sapply(out, function(y) y$subactivity[1])
#'
#' # use CAS-numbers
#' bcpc_query("79622-59-6", from = 'cas')
#' }
bcpc_query <- function(query, from = c("name", "cas","rn","cn","fr","en","zh","ru","inchikey"),
                       verbose = getOption("verbose"),
                       type, ...) {

  if (!ping_service("bcpc")) stop(webchem_message("service_down"))

  # Deprecations messages
  if (!missing(type)) {
    message('"type" is deprecated. Please use "from" instead. ')
    from <- type
  }
  if ("commonname" %in% from) {
    message('To search by compound name use "name" instead of "commonname"')
    from <- "name"
  }

  from <- match.arg(from)
  from <- convert_from_arg_bcpc(from)
  bcpc_idx <- build_bcpc_idx(verbose = verbose, ...)
  names(query) <- query
  out <- lapply(query, function(x) scrape_bcpc_frame(x, from = from, idx = bcpc_idx, verbose = verbose))
  class(out) <- c("bcpc_query", "list")
  return(out)
}

#' Function to build index
#'
#' This function builds an index of the BCPC Compendium of Pesticides
#' and saves it to \code{\link{tempdir}}.
#' @import xml2
#'
#' @param verbose logical; print message during processing to console?
#' @param force_build logical; force building a new index?
#' @return a data.frame
#' @seealso \code{\link{bcpc_query}}, \code{\link{tempdir}}
#' @source \url{https://pesticidecompendium.bcpc.org}
#' @noRd
build_bcpc_idx <- function(sources = c("rn", "inchikey", "cn", "fr", "ru", "zh"), verbose = getOption("verbose"), force_build = FALSE) {
  if (!ping_service("bcpc")) stop(webchem_message("service_down"))
  suppressWarnings(try(load(paste0(tempdir(), "/data/bcpc_idx.rda")),
                       silent = TRUE))
  if (!file.exists(paste0(tempdir(), "/data/bcpc_idx.rda")) ||
      force_build ||
      try(Sys.Date() - attr(bcpc_idx, "date"), silent = TRUE) > 30) {
    if (!dir.exists(paste0(tempdir(), "/data"))) {
      dir.create(paste0(tempdir(), "/data"))
    }
    sources <- match.arg(sources, several.ok = TRUE)
    if (verbose) message("Building index. ", appendLF = FALSE)
    idx_sources <- data.frame(
      name = c("rn", "inchikey", "cn", "fr", "ru", "zh"),
      code = c(TRUE, TRUE, FALSE, FALSE, FALSE, FALSE),
      url = c(
        "https://pesticidecompendium.bcpc.org/index_rn.html",
        "www.bcpcpesticidecompendium.org/index-inchikey.html",
        "https://pesticidecompendium.bcpc.org/index_cn.html",
        "https://pesticidecompendium.bcpc.org/index-fr.html",
        "https://pesticidecompendium.bcpc.org/index-ru.html",
        "https://pesticidecompendium.bcpc.org/index-zh.html"
      )
    )
    selected <- subset(idx_sources, idx_sources$name %in% sources)
    idxs <- apply(selected, 1, function(source) {
      res <- query_bcpc_url(source[["url"]])
      if (source[["code"]]) {
        idx <- prep_idx_code(res, source = source[["name"]])
      } else {
        idx <- prep_idx_named(res, source = source[["name"]], xpath = "//p/a")
      }
    })
    bcpc_idx <- do.call(rbind, idxs)
    # fix encoding
    ln <- bcpc_idx$linknames
    ln <- iconv(ln, to = "UTF-8", sub = "")#is it necessary?
    bcpc_idx$linknames <- ln
    attr(bcpc_idx, "date") <- Sys.Date()
    save(bcpc_idx, file = paste0(tempdir(), "/data/bcpc_idx.rda"))
  }
  return(bcpc_idx)
}

#' Function to query bcpc and handle httr errors
#'
#' This function returns an httr response object
#' @param url string; uri to query
#' @param verbose logical; print message during processing to console?
#' @return Httr response object
#' @noRd
query_bcpc_url <- function(url, verbose = getOption("verbose")) {
  res <- try(
    httr::RETRY(
      "GET",
      url,
      httr::user_agent(webchem_url()),
      config = httr::config(accept_encoding = "identity"),
      terminate_on = 404,
      quiet = TRUE
    ),
    silent = TRUE
  )
  if (inherits(res, "try-error")) {
    if (verbose) webchem_message("service_down")
    return(NA)
  }
  if (verbose) message(httr::message_for_status(res))
  if (res$status_code == 200) return(res)
}

#' Function scrape link names and urls from an httr response of a code (CAS, IUPAC, etc.) bcpc index frame
#'
#' This function returns a dataframe of linknames, links and sources
#' @param res httr response object to scrape
#' @param source string of response source
#' @return data.frame
#' @seealso \code{\link{build_bcpc_idx}} for referring function,
#' for named index frame, use \code{\link{prep_idx_named}}
#' @noRd
prep_idx_code <- function(res, source) {
  idx <- read_html(res)
  names <- xml_text(xml_find_all(idx, "//dl/dt"))
  links <- xml_attr(
    xml_find_all(idx, "//dt/following-sibling::dd[1]/a[1]"), "href"
  )
  linknames <- xml_text(
    xml_find_all(idx, "//dt/following-sibling::dd[1]/a[1]")
  )
  df_idx <- data.frame(names, links, linknames, stringsAsFactors = FALSE)
  df_idx[["source"]] <- source
  return(df_idx)
}

#' Scrapes link names and urls from an httr response of a named bcpc index frame
#'
#' This function returns a dataframe of linknames, links and sources
#' @param res httr response object to scrape
#' @param source string of response source
#' @param xpath a string of an xpath
#' @return data.frame
#' @seealso \code{\link{build_bcpc_idx}} for referring function,
#' for coded index frame, use \code{\link{prep_idx_named}}
#' @noRd
prep_idx_named <- function(res, source, xpath) {
  idx <- read_html(res)
  n <- xml_find_all(idx, xpath)
  names <- xml_text(n)
  keep <- nzchar(names)
  names <- names[keep]
  links <- xml_attr(n, "href")[keep]
  data.frame(
    names = names,
    links = links,
    linknames = names,
    source = source,
    stringsAsFactors = FALSE
  )
}

#' Function to handle synonymous arguments
#'
#' This function returns a dataframe of linknames, links and sources
#' @param from argument (single) string
#' @return string
#' @seealso \code{\link{bcpc_query}}
#' @noRd
convert_from_arg_bcpc <- function(from) {
  from <- gsub("name|name_en", "cn", from)
  from <- gsub("cas", "rn", from)
  from
}

#' Function to scrape information from a substance page
#'
#' This function returns a named list of substance attributes and values
#' @param query string to query in index
#' @param from source argument
#' @param idx data.frame of bcpc index
#' @return named list
#' @seealso \code{\link{bcpc_query}}, \code{\link{build_bcpc_idx}}
#' @noRd
scrape_bcpc_frame <- function(query, from, idx, verbose) {
  idx <- subset(idx, source == from)
  if (is.na(query)) {
    if (verbose) webchem_message("na")
    return(NA)
  }
  if (verbose) webchem_message("query", query, appendLF = FALSE)
  # generic selection
  if (from == "cas") query <- as.cas(query, verbose = verbose)
  names <- idx$names
  links <- idx$links
  linknames <- idx$linknames
  cname <- linknames[tolower(names) == tolower(query)]
  takelink <- links[tolower(names) == tolower(query)]
  # end new
  # search links in indexes
  if (length(takelink) == 0) {
    if (verbose) message("Not found.")
    return(NA)
  }
  if (length(takelink) > 1) {
    takelink <- unique(takelink)
    if (length(takelink) > 1) {
      message("More then one link found. Returning first.")
      takelink <- takelink[1]
    }
  }

  qurl <- paste0("https://pesticidecompendium.bcpc.org/", takelink)
  webchem_sleep(type = "scrape")
  res <- query_bcpc_url(qurl)
  if (!length(res) || !res$status_code == 200) {
    return(NA)
  }

  ttt <- read_html(res)
  status <- xml_text(
    xml_find_all(ttt, "//tr/th[@id='r1']/following-sibling::td")
  )
  name_fr <- xml_find_all(ttt, "//h2/span/following::span[@lang='fr'][1]")
  # remove noun gender
  name_fr <- xml_text(
    read_xml(
      gsub(" \\(<abbr.*>.*<\\/abbr>\\)", "", name_fr)
    )
  )
  name_ru <- xml_text(
    xml_find_all(ttt, "//h2/span/following::span[@lang='ru'][1]")
  )
  name_zh <- xml_text(
    xml_find_all(ttt, "//h2/span/following::span[@lang='zh-Hans'][1]")
  )
  pref_iupac_name <- xml_text(
    xml_find_all(ttt, "//tr/th[@id='r2']/following-sibling::td")
  )
  iupac_name <- xml_text(
    xml_find_all(ttt, "//tr/th[@id='r3']/following-sibling::td")
  )
  cas <- xml_text(
    xml_find_all(ttt, "//tr/th[@id='r5']/following-sibling::td")
  )
  formula <- xml_text(
    xml_find_all(ttt, "//tr/th[@id='r6']/following-sibling::td")
  )
  activity_text <- as.character(xml_find_all(ttt, "//tr/th[@id='r7']/following-sibling::td"))
  a_tmp_1 <- trimws(gsub("<td.*?>(.*)</td>", "\\1", activity_text))
  a_tmp_2 <- gsub("<a.*?>", "", a_tmp_1)
  a_tmp_3 <- gsub("</a>", "", a_tmp_2)
  a_split <- strsplit(a_tmp_3, "<br>")[[1]]
  activity <- unname(sapply(a_split, function(x) gsub(" \\(.*\\)$", "", x)))
  subactivity <- unname(sapply(a_split, function(x) {
    if (grepl("\\(.*\\)", x)) {
      gsub(".*\\((.*)\\)$", "\\1", x)
    } else {
      NA
    }
  }))
  inchikey_r <- xml_text(
    xml_find_all(ttt, "//tr/th[@id='r11']/following-sibling::td")
  )
  if (length(inchikey_r) == 0) {
    inchikey <- NA
  } else {
    if (grepl("isomer", inchikey_r)) {
      inchikey <- c(
        s_isomer = gsub(
          ".*\\(S\\)-isomer:(.*)(minor component.*)", "\\1", inchikey_r
        ),
        r_isomer = gsub(".*\\(R\\)-isomer:(.*)", "\\1", inchikey_r)
      )
    }
    if (grepl("identifier", inchikey_r)) {
      inchikey <- c(
        gsub("(.*)identifier.*", "\\1", inchikey_r),
        gsub(".*identifier.*:(.*)", "\\1", inchikey_r)
      )
      names(inchikey) <- c(
        "inchikey",
        gsub(".*(identifier.*:).*", "\\1", inchikey_r)
      )
    }
    if (!grepl("isomer", inchikey_r) & !grepl("identifier", inchikey_r)) {
      inchikey <- inchikey_r
    }
  }

  inchi <- xml_text(
    xml_find_all(ttt, "//tr/th[@id='r12']/following-sibling::td")
  )
  if (length(inchi) == 0) {
    inchi <- NA
  } else {
    if (grepl("isomer", inchi)) {
      inchi <- c(
        s_isomer = gsub(
          ".*\\(S\\)-isomer:(.*)(minor component.*)",
          "\\1", inchi
        ),
        r_isomer = gsub(".*\\(R\\)-isomer:(.*)", "\\1", inchi)
      )
    }
  }
  out <- list(
    cname = cname,
    name_fr = name_fr,
    name_ru = name_ru,
    name_zh = name_zh,
    status = status,
    pref_iupac_name = pref_iupac_name, iupac_name = iupac_name,
    cas = cas, formula = formula, activity = activity,
    subactivity = subactivity, inchikey = inchikey, inchi = inchi,
    source_url = qurl
  )
  return(out)
}